{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.ToTensor()\n",
    "\n",
    "train_data=datasets.MNIST('./data/', train=True,\n",
    "                          transform=transform, download=True)\n",
    "test_data=datasets.MNIST('./data/', train=False,\n",
    "                          transform=transform, download=True)\n",
    "\n",
    "num_workers=0\n",
    "batch_size=64\n",
    "train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visulize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter=iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.shape, labels.shape)\n",
    "\n",
    "images=images.numpy()\n",
    "img=np.squeeze(images[0])\n",
    "\n",
    "fig=plt.figure(figsize=(3,3))\n",
    "ax=fig.add_subplot(1,1,1)\n",
    "ax.imshow(img, cmap='gray')\n",
    "ax.set_title(labels[0].item())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (dropout): Dropout(p=0.3)\n",
      "  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.fc1=nn.Linear(input_size, hidden_size*4)\n",
    "        self.fc2=nn.Linear(hidden_size*4, hidden_size*2)\n",
    "        self.fc3=nn.Linear(hidden_size*2, hidden_size)\n",
    "        \n",
    "        self.dropout=nn.Dropout(0.3)\n",
    "\n",
    "        self.fc4=nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=x.view(-1, 28*28)\n",
    "        x=F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x=self.dropout(x)\n",
    "        x=F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x=self.dropout(x)\n",
    "        x=F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x=self.dropout(x)\n",
    "        out=self.fc4(x)\n",
    "        return out\n",
    "    \n",
    "d_input_size=28*28\n",
    "d_hidden_size=32\n",
    "d_output_size=1\n",
    "\n",
    "D = Discriminator(d_input_size, d_hidden_size, d_output_size)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (dropout): Dropout(p=0.3)\n",
      "  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "Generator(\n",
      "  (fc1): Linear(in_features=100, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (dropout): Dropout(p=0.3)\n",
      "  (fc4): Linear(in_features=128, out_features=784, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc1=nn.Linear(input_size, hidden_size)\n",
    "        self.fc2=nn.Linear(hidden_size, hidden_size*2)\n",
    "        self.fc3=nn.Linear(hidden_size*2, hidden_size*4)\n",
    "        \n",
    "        self.dropout=nn.Dropout(0.3)\n",
    "\n",
    "        self.fc4=nn.Linear(hidden_size*4, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x=self.dropout(x)\n",
    "        x=F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x=self.dropout(x)\n",
    "        x=F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x=self.dropout(x)\n",
    "        out=F.tanh(self.fc4(x))\n",
    "        return out\n",
    "    \n",
    "g_input_size=100\n",
    "g_hidden_size=32\n",
    "g_output_size=28*28\n",
    "\n",
    "G=Generator(g_input_size, g_hidden_size, g_output_size)\n",
    "print(D)\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator and Generator Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_loss(D_out, smooth=False):\n",
    "    batch_size=D_out.size(0)\n",
    "    if smooth:\n",
    "        labels=torch.ones(batch_size)*0.9\n",
    "    else:\n",
    "        labels=torch.ones(batch_size)\n",
    "    \n",
    "    criterion=nn.BCEWithLogitsLoss()\n",
    "    loss=criterion(D_out.squeeze(), labels)\n",
    "    return loss\n",
    "\n",
    "def fake_loss(D_out):\n",
    "    batch_size=D_out.size(0)\n",
    "    labels=torch.zeros(batch_size)\n",
    "    criterion=nn.BCEWithLogitsLoss()\n",
    "    loss=criterion(D_out.squeeze(), labels)\n",
    "    return loss        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.002\n",
    "d_optimizer=optim.Adam(D.parameters(), lr)\n",
    "g_optimizer=optim.Adam(G.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [    1/    5] | d_loss: 3.1048 | g_loss: 0.8446\n",
      "Epoch [    1/    5] | d_loss: 1.9551 | g_loss: 0.7459\n",
      "Epoch [    2/    5] | d_loss: 1.2846 | g_loss: 0.8876\n",
      "Epoch [    2/    5] | d_loss: 1.2570 | g_loss: 1.8389\n",
      "Epoch [    3/    5] | d_loss: 1.3714 | g_loss: 1.0527\n",
      "Epoch [    3/    5] | d_loss: 0.9488 | g_loss: 2.3094\n",
      "Epoch [    4/    5] | d_loss: 0.8867 | g_loss: 2.6263\n",
      "Epoch [    4/    5] | d_loss: 1.1596 | g_loss: 1.1080\n",
      "Epoch [    5/    5] | d_loss: 1.1570 | g_loss: 2.0669\n",
      "Epoch [    5/    5] | d_loss: 1.1091 | g_loss: 1.2791\n"
     ]
    }
   ],
   "source": [
    "num_epochs=5\n",
    "samples=[]\n",
    "losses=[]\n",
    "print_every=400\n",
    "\n",
    "sample_size=16\n",
    "fixed_z=np.random.uniform(-1,1, size=(sample_size, g_input_size))\n",
    "fixed_z=torch.from_numpy(fixed_z).float()\n",
    "print(fixed_z.shape)\n",
    "\n",
    "D.train()\n",
    "G.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch_i, (real_images,_) in enumerate(train_loader, 1):\n",
    "        batch_size=real_images.size(0)\n",
    "        real_images=real_images*2-1\n",
    "        \n",
    "        #\n",
    "        # DISCRIMINATOR TRAIN\n",
    "        #\n",
    "        \n",
    "        d_optimizer.zero_grad()\n",
    "        D_real=D(real_images)\n",
    "        d_real_loss=real_loss(D_real, smooth=True)\n",
    "        \n",
    "        z=np.random.uniform(-1, 1, size=(batch_size, g_input_size))\n",
    "        z=torch.from_numpy(z).float()\n",
    "        fake_images=G(z)\n",
    "        \n",
    "        D_fake=D(fake_images)\n",
    "        d_fake_loss=fake_loss(D_fake)\n",
    "        \n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        #\n",
    "        # GENERATOR TRAIN\n",
    "        #\n",
    "        g_optimizer.zero_grad()\n",
    "        z=np.random.uniform(-1, 1, size=(batch_size, g_input_size))\n",
    "        z=torch.from_numpy(z).float()\n",
    "        fake_images=G(z)\n",
    "        D_fake=D(fake_images)\n",
    "        g_loss=real_loss(D_fake)\n",
    "        \n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # Print some loss stats\n",
    "        # Print some loss stats\n",
    "        if batch_i % print_every == 0:\n",
    "            # print discriminator and generator loss\n",
    "            print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
    "                    epoch+1, num_epochs, d_loss.item(), g_loss.item()))        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
